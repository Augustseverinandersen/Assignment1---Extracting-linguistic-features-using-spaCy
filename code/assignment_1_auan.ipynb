{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment concerns using ```spaCy``` to extract linguistic information from a corpus of texts.\n",
    "\n",
    "The corpus is an interesting one: *The Uppsala Student English Corpus (USE)*. All of the data is included in the folder called ```in``` but you can access more documentation via [this link](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/2457).\n",
    "\n",
    "For this exercise, you should write some code which does the following:\n",
    "\n",
    "- Loop over each text file in the folder called ```in```\n",
    "- Extract the following information:\n",
    "    - Relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words\n",
    "    - Total number of *unique* PER, LOC, ORGS\n",
    "- For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:\n",
    "\n",
    "|Filename|RelFreq NOUN|RelFreq VERB|RelFreq ADJ|RelFreq ADV|Unique PER|Unique LOC|Unique ORG|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|file1.txt|---|---|---|---|---|---|---|\n",
    "|file2.txt|---|---|---|---|---|---|---|\n",
    "|etc|---|---|---|---|---|---|---|\n",
    "\n",
    "## Objective\n",
    "\n",
    "This assignment is designed to test that you can:\n",
    "\n",
    "1. Work with multiple input data arranged hierarchically in folders;\n",
    "2. Use ```spaCy``` to extract linguistic information from text data;\n",
    "3. Save those results in a clear way which can be shared or used for future analysis\n",
    "\n",
    "## Some notes\n",
    "\n",
    "- The data is arranged in various subfolders related to their content (see the [README](in/README.md) for more info). You'll need to think a little bit about how to do this. You should be able do it using a combination of things we've already looked at, such as ```os.listdir()```, ```os.path.join()```, and for loops.\n",
    "- The text files contain some extra information that such as document ID and other metadata that occurs between pointed brackets ```<>```. Make sure to remove these as part of your preprocessing steps!\n",
    "- There are 14 subfolders (a1, a2, a3, etc), so when completed the folder ```out``` should have 14 CSV files.\n",
    "\n",
    "## Additional comments\n",
    "\n",
    "Your code should include functions that you have written wherever possible. Try to break your code down into smaller self-contained parts, rather than having it as one long set of instructions.\n",
    "\n",
    "For this assignment, you are welcome to submit your code either as a Jupyter Notebook, or as ```.py``` script. If you do not know how to write ```.py``` scripts, don't worry - we're working towards that!\n",
    "\n",
    "Lastly, you are welcome to edit this README file to contain whatever informatio you like. Remember - documentation is important!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a spacy NLP class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\") # loads the entire model spacy into the variable nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on one text first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for extracting nouns and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_attributes (filename):\n",
    "    filepath = os.path.join(\"..\", \"in\", \"USEcorpus\", \"c1\", filename) # define file path, with open file name\n",
    "    with open(filepath, \"r\", encoding=\"latin-1\") as file: # open the file and encode using utf 8\n",
    "        text = file.read()\n",
    "    text = re.sub(r'<.*?>', '', text) # remove all characters between < > \n",
    "    doc = nlp(text) # use spacy nlp  to create and find tokens.\n",
    "\n",
    "    # finding relFreg of nouns\n",
    "    noun_count =0 # creating empty variables \n",
    "    verb_count =0\n",
    "    adjective_count = 0\n",
    "    adverb_count = 0\n",
    "\n",
    "    for token in doc: # for loop that counts the number of times each adj, noun, verb and adv accours.\n",
    "        if token.pos_ ==\"ADJ\":\n",
    "            adjective_count +=1\n",
    "        elif token.pos_ == \"NOUN\":\n",
    "            noun_count += 1\n",
    "        elif token.pos_ == \"VERB\":\n",
    "            verb_count +=1\n",
    "        elif token.pos_ == \"ADV\":\n",
    "            adverb_count += 1\n",
    "\n",
    "    relative_freq_ADJ = (adjective_count/len(doc)) * 10000 # finding the relative frequence and storing in variable \n",
    "    relative_freq_ADJ = round(relative_freq_ADJ, 2)\n",
    "    relative_freq_NOUN = (noun_count/len(doc)) * 10000\n",
    "    relative_freq_NOUN = round(relative_freq_NOUN, 2)\n",
    "    relative_freq_VERB = (verb_count/len(doc)) * 10000\n",
    "    relative_freq_VERB = round(relative_freq_VERB, 2)\n",
    "    relative_freq_ADV = (adverb_count/len(doc)) * 10000\n",
    "    relative_freq_ADV = round(relative_freq_ADV, 2)\n",
    "    # Finding Unique PER; LOC, ORG\n",
    "    entities_PER = [] # creating empty list\n",
    "    entities_LOC = []\n",
    "    entities_ORG = []\n",
    "\n",
    "# get named entities and add to list \n",
    "    for ent in doc.ents: # ent means entity # for loop that finds each word with either person, loc or org and appends to the matching variable \n",
    "        if ent.label_ == \"PERSON\": \n",
    "            entities_PER.append(ent.text)\n",
    "        elif ent.label_ == \"LOC\":\n",
    "            entities_LOC.append(ent.text)\n",
    "        elif ent.label_ == \"ORG\":\n",
    "            entities_ORG.append(ent.text)\n",
    "\n",
    "    unique_entities_PER = set(entities_PER) # defining unique only \n",
    "    unique_entities_LOC = set(entities_LOC)\n",
    "    unique_entities_ORG = set(entities_ORG) # using set to find the unique entities in the list.\n",
    "    # checking to see if it has worked so far \n",
    "    #print(filename, relative_freq_NOUN, relative_freq_VERB, relative_freq_ADJ, relative_freq_ADV, unique_entities_PER, unique_entities_LOC, unique_entities_ORG)\n",
    "    \n",
    "    # creating a dictionary so i can store the data in a pandas dataframe \n",
    "    #datadic = [\n",
    "    #{\"Filename\": filename, \"RelFreq NOUN\": relative_freq_NOUN, \"RelFreq VERB\": relative_freq_VERB, \"RelFreq ADJ\": relative_freq_ADJ, \"RelFreq ADV\": relative_freq_ADV, \"Unique PER\": unique_entities_PER, \"Unique LOC\": unique_entities_LOC, \"Unique ORG\": unique_entities_ORG}\n",
    "#]\n",
    "    #touple_of_data = []\n",
    "    #for doc in [filename]:\n",
    "        #touple_of_data.append((doc, relative_freq_NOUN, relative_freq_VERB, relative_freq_ADJ, relative_freq_ADV, unique_entities_PER, unique_entities_LOC, unique_entities_ORG))\n",
    "    #print(touple_of_data)\n",
    "    #all_tuples = []\n",
    "    touple_of_data = []\n",
    "    \n",
    "   \n",
    "    for doc in [filename]:\n",
    "        touple_of_data.append((filename, relative_freq_NOUN, relative_freq_VERB, relative_freq_ADJ, relative_freq_ADV, unique_entities_PER, unique_entities_LOC, unique_entities_ORG))\n",
    "        data = pd.DataFrame(touple_of_data, columns=['Filename', 'Noun Freq', 'Verb Freq', 'Adj Freq', 'Adv Freq', 'Unique PER', 'Unique LOC', 'Unique ORG'])\n",
    "    \n",
    "    return data\n",
    "# creating a pandas dataframe, and storing in out folder as a csv file\n",
    "    outpath = os.path.join(\"..\", \"out\", filename + \"annotations.csv\") # creating variable which works like a function for code below\n",
    "    #data.to_csv(outpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../in/USEcorpus/c1/0100.a1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m find_attributes(\u001b[39m\"\u001b[39;49m\u001b[39m0100.a1.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mfind_attributes\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_attributes\u001b[39m (filename):\n\u001b[1;32m      2\u001b[0m     filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39min\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUSEcorpus\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mc1\u001b[39m\u001b[39m\"\u001b[39m, filename) \u001b[39m# define file path, with open file name\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filepath, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m file: \u001b[39m# open the file and encode using utf 8\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         text \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<.*?>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text) \u001b[39m# remove all characters between < > \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../in/USEcorpus/c1/0100.a1.txt'"
     ]
    }
   ],
   "source": [
    "find_attributes(\"0100.a1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_new = os.path.join(\"..\", \"in\", \"USEcorpus\", \"c1\")\n",
    "dataframes = []\n",
    "for file in os.listdir(filepath_new):\n",
    "    testone = os.path.join(filepath_new, file)\n",
    "    data = find_attributes(file)\n",
    "    dataframes.append(data)\n",
    "final_data = pd.concat(dataframes)\n",
    "final_data\n",
    "\n",
    "outpath = os.path.join(\"..\", \"out\", \"df.csv\") # creating variable which works like a function for code below\n",
    "final_data.to_csv(outpath)\n",
    "#print(dataframes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Noun Freq</th>\n",
       "      <th>Verb Freq</th>\n",
       "      <th>Adj Freq</th>\n",
       "      <th>Adv Freq</th>\n",
       "      <th>Unique PER</th>\n",
       "      <th>Unique LOC</th>\n",
       "      <th>Unique ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0176.a1.txt</td>\n",
       "      <td>1408.14</td>\n",
       "      <td>1243.12</td>\n",
       "      <td>649.06</td>\n",
       "      <td>682.07</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Visingsö Folk High School}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040.a1.txt</td>\n",
       "      <td>1168.09</td>\n",
       "      <td>1737.89</td>\n",
       "      <td>940.17</td>\n",
       "      <td>655.27</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2044.a1.txt</td>\n",
       "      <td>1398.96</td>\n",
       "      <td>1450.78</td>\n",
       "      <td>556.99</td>\n",
       "      <td>595.85</td>\n",
       "      <td>{Marie Antoinette}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102.a1.txt</td>\n",
       "      <td>1198.63</td>\n",
       "      <td>1381.28</td>\n",
       "      <td>730.59</td>\n",
       "      <td>730.59</td>\n",
       "      <td>{katt, Britsh, Minette Walters, superintendet ...</td>\n",
       "      <td>{Africa, Asia}</td>\n",
       "      <td>{instace}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1029.a1.txt</td>\n",
       "      <td>1342.04</td>\n",
       "      <td>1330.17</td>\n",
       "      <td>748.22</td>\n",
       "      <td>439.43</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1008.a1.txt</td>\n",
       "      <td>1468.86</td>\n",
       "      <td>1316.10</td>\n",
       "      <td>564.04</td>\n",
       "      <td>634.55</td>\n",
       "      <td>{Grammar}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0112.a1.txt</td>\n",
       "      <td>1314.22</td>\n",
       "      <td>1278.38</td>\n",
       "      <td>788.53</td>\n",
       "      <td>681.00</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{listeng}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0191.a1.txt</td>\n",
       "      <td>1257.49</td>\n",
       "      <td>1365.27</td>\n",
       "      <td>754.49</td>\n",
       "      <td>682.63</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{CNN, American Social Studies}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1096.a1.txt</td>\n",
       "      <td>1250.00</td>\n",
       "      <td>1363.64</td>\n",
       "      <td>670.45</td>\n",
       "      <td>727.27</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Zodiac}</td>\n",
       "      <td>{University}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0162.a1.txt</td>\n",
       "      <td>1210.27</td>\n",
       "      <td>1259.17</td>\n",
       "      <td>660.15</td>\n",
       "      <td>611.25</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{yars}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename  Noun Freq  Verb Freq  Adj Freq  Adv Freq  \\\n",
       "0   0176.a1.txt    1408.14    1243.12    649.06    682.07   \n",
       "0   3040.a1.txt    1168.09    1737.89    940.17    655.27   \n",
       "0   2044.a1.txt    1398.96    1450.78    556.99    595.85   \n",
       "0   1102.a1.txt    1198.63    1381.28    730.59    730.59   \n",
       "0   1029.a1.txt    1342.04    1330.17    748.22    439.43   \n",
       "..          ...        ...        ...       ...       ...   \n",
       "0   1008.a1.txt    1468.86    1316.10    564.04    634.55   \n",
       "0   0112.a1.txt    1314.22    1278.38    788.53    681.00   \n",
       "0   0191.a1.txt    1257.49    1365.27    754.49    682.63   \n",
       "0   1096.a1.txt    1250.00    1363.64    670.45    727.27   \n",
       "0   0162.a1.txt    1210.27    1259.17    660.15    611.25   \n",
       "\n",
       "                                           Unique PER      Unique LOC  \\\n",
       "0                                                  {}              {}   \n",
       "0                                                  {}              {}   \n",
       "0                                  {Marie Antoinette}              {}   \n",
       "0   {katt, Britsh, Minette Walters, superintendet ...  {Africa, Asia}   \n",
       "0                                                  {}              {}   \n",
       "..                                                ...             ...   \n",
       "0                                           {Grammar}              {}   \n",
       "0                                                  {}              {}   \n",
       "0                                                  {}              {}   \n",
       "0                                                  {}        {Zodiac}   \n",
       "0                                                  {}              {}   \n",
       "\n",
       "                        Unique ORG  \n",
       "0      {Visingsö Folk High School}  \n",
       "0                               {}  \n",
       "0                               {}  \n",
       "0                        {instace}  \n",
       "0                               {}  \n",
       "..                             ...  \n",
       "0                               {}  \n",
       "0                        {listeng}  \n",
       "0   {CNN, American Social Studies}  \n",
       "0                     {University}  \n",
       "0                           {yars}  \n",
       "\n",
       "[303 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
